{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c2436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Mundo\n"
     ]
    }
   ],
   "source": [
    "print(\"Hola Mundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382d425",
   "metadata": {},
   "source": [
    "## Pipeline y prototipo de detección de eventos\n",
    "Este notebook añade un pipeline mínimo para:\n",
    "- Cargar `data/dataset/england_epl.pkl`\n",
    "- Convertir `annotations` a etiquetas por frame (asumiendo `position` en ms -> frame = position//1000)\n",
    "- Preparar ventanas temporales (secuencias)\n",
    "- Definir un modelo temporal pequeño (Conv1D) en PyTorch\n",
    "- Hacer un smoke test para validar shapes\n",
    "\n",
    "Eventos objetivo por defecto: `['Goal', 'Shots on target']`. Si quieres otros eventos, indícalos y lo modifico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c1462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: 49\n",
      "num_frames example: 5690\n",
      "labels0 shape: (5690, 2) sum per class: [ 4. 24.]\n",
      "per-camera frame counts: [5690, 5828]\n",
      "Warning: unequal frame counts [5690, 5828], truncating to min=5690\n",
      "combined feature shape: (5690, 1024)\n",
      "match 0: [5690, 5828]\n",
      "match 1: [5679, 5619]\n",
      "match 2: [5400, 5399]\n",
      "match 3: [5400, 5400]\n",
      "match 4: [5964, 6174]\n",
      "match 5: [5400, 5399]\n",
      "Using dataset: data/dataset/england_epl_2015-2016.pkl\n",
      "Using dataset: data/dataset/england_epl_2015-2016.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos y convertir anotaciones a etiquetas por frame\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Preferir dataset pequeño para pruebas rápidas si existe\n",
    "PKL_SMALL = 'data/dataset/england_epl_2015-2016.pkl'\n",
    "PKL_FULL = 'data/dataset/england_epl.pkl'\n",
    "DATA_PKL = PKL_SMALL if os.path.exists(PKL_SMALL) else PKL_FULL\n",
    "TARGET_EVENTS = ['Goal', 'Shots on target']  # modificar si quieres otros eventos\n",
    "\n",
    "with open(DATA_PKL, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_all = data['X']  # lista de partidos; cada partido es lista de arrays por cámara\n",
    "y_all = data['y']\n",
    "\n",
    "print('matches:', len(X_all))\n",
    "\n",
    "# Función para convertir annotations a array por frame\n",
    "def annotations_to_frame_labels(annotations, num_frames, target_events):\n",
    "    # annotations: lista de dicts con 'label' y 'position' (ms)\n",
    "    n_classes = len(target_events)\n",
    "    labels = np.zeros((num_frames, n_classes), dtype=np.float32)\n",
    "    label_to_idx = {lab: i for i, lab in enumerate(target_events)}\n",
    "    for ann in annotations:\n",
    "        lab = ann.get('label')\n",
    "        pos = ann.get('position')\n",
    "        if lab in label_to_idx and pos is not None:\n",
    "            try:\n",
    "                pos_ms = int(pos)\n",
    "            except Exception:\n",
    "                continue\n",
    "            frame = int(pos_ms // 1000)\n",
    "            if frame < 0:\n",
    "                continue\n",
    "            if frame >= num_frames:\n",
    "                frame = num_frames - 1\n",
    "            labels[frame, label_to_idx[lab]] = 1.0\n",
    "    return labels\n",
    "\n",
    "# Ejemplo en primer partido\n",
    "first_X = X_all[0]\n",
    "num_frames = first_X[0].shape[0]\n",
    "print('num_frames example:', num_frames)\n",
    "labels0 = annotations_to_frame_labels(y_all[0]['annotations'], num_frames, TARGET_EVENTS)\n",
    "print('labels0 shape:', labels0.shape, 'sum per class:', labels0.sum(axis=0))\n",
    "\n",
    "# Combinar cámaras: concatenamos features por eje de características\n",
    "def combine_cameras(X_match, mode='min'):\n",
    "    \"\"\"Combina una lista de arrays por frame.\n",
    "    Si las longitudes difieren: mode='min' trunca a min, mode='pad' rellena con ceros\n",
    "    \"\"\"\n",
    "    if not isinstance(X_match, list):\n",
    "        raise ValueError('X_match debe ser una lista de arrays')\n",
    "    lengths = [arr.shape[0] for arr in X_match]\n",
    "    print('per-camera frame counts:', lengths)\n",
    "    if len(set(lengths)) == 1:\n",
    "        return np.concatenate(X_match, axis=1)\n",
    "    if mode == 'min':\n",
    "        min_len = min(lengths)\n",
    "        truncated = [arr[:min_len] for arr in X_match]\n",
    "        print(f'Warning: unequal frame counts {lengths}, truncating to min={min_len}')\n",
    "        return np.concatenate(truncated, axis=1)\n",
    "    elif mode == 'pad':\n",
    "        max_len = max(lengths)\n",
    "        padded = []\n",
    "        for arr in X_match:\n",
    "            if arr.shape[0] < max_len:\n",
    "                pad = np.zeros((max_len - arr.shape[0], arr.shape[1]), dtype=arr.dtype)\n",
    "                padded.append(np.vstack([arr, pad]))\n",
    "            else:\n",
    "                padded.append(arr)\n",
    "        return np.concatenate(padded, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'min' or 'pad'\")\n",
    "\n",
    "X0_comb = combine_cameras(first_X, mode='min')\n",
    "print('combined feature shape:', X0_comb.shape)\n",
    "\n",
    "# Debug: imprimir conteo de frames por cámara para las primeras partidas\n",
    "\n",
    "for mi, Xm in enumerate(X_all[:6]):\n",
    "    lens = [arr.shape[0] for arr in Xm]\n",
    "    print(f'match {mi}: {lens}')\n",
    "\n",
    "print('Using dataset:', DATA_PKL)\n",
    "print('Using dataset:', DATA_PKL)# Nota: para pruebas rápidas usamos el archivo smaller PKL si está presente    print(f'match {mi}: {lens}')    lens = [arr.shape[0] for arr in Xm]for mi, Xm in enumerate(X_all[:6]):Sample camera frame counts for first 6 matches:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5871599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: unequal frame counts [5690, 5828], truncating to min=5690\n",
      "Warning: unequal frame counts [5679, 5619], truncating to min=5619\n",
      "Warning: unequal frame counts [5400, 5399], truncating to min=5399\n",
      "feature dim: 1024\n",
      "Normalized X_small using computed mean/std\n",
      "dataset samples: 4400\n",
      "batch x shape: torch.Size([8, 30, 1024]) batch y shape: torch.Size([8, 30, 2])\n"
     ]
    }
   ],
   "source": [
    "# Dataset y DataLoader PyTorch (uso de secuencias)\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEQUENCE_LENGTH = 30  # seconds (frames), ajusta según necesites\n",
    "STRIDE = 5\n",
    "\n",
    "# Función robusta para combinar cámaras\n",
    "def combine_cameras(X_match, mode='min'):\n",
    "    \"\"\"Combina una lista de arrays por frame.\n",
    "    Si las longitudes difieren:\n",
    "      - mode='min': trunca todas a la longitud mínima\n",
    "      - mode='pad': rellena con ceros hasta la longitud máxima\n",
    "    Retorna un array (num_frames, total_feat_dim)\n",
    "    \"\"\"\n",
    "    if not isinstance(X_match, list):\n",
    "        raise ValueError('X_match debe ser una lista de arrays')\n",
    "    lengths = [arr.shape[0] for arr in X_match]\n",
    "    if len(set(lengths)) == 1:\n",
    "        return np.concatenate(X_match, axis=1)\n",
    "\n",
    "    if mode == 'min':\n",
    "        min_len = min(lengths)\n",
    "        if min_len == 0:\n",
    "            raise ValueError('Una de las cámaras tiene 0 frames')\n",
    "        truncated = [arr[:min_len] for arr in X_match]\n",
    "        print(f\"Warning: unequal frame counts {lengths}, truncating to min={min_len}\")\n",
    "        return np.concatenate(truncated, axis=1)\n",
    "    elif mode == 'pad':\n",
    "        max_len = max(lengths)\n",
    "        padded = []\n",
    "        for arr in X_match:\n",
    "            if arr.shape[0] < max_len:\n",
    "                pad = np.zeros((max_len - arr.shape[0], arr.shape[1]), dtype=arr.dtype)\n",
    "                padded.append(np.vstack([arr, pad]))\n",
    "            else:\n",
    "                padded.append(arr)\n",
    "        return np.concatenate(padded, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'min' or 'pad'\")\n",
    "\n",
    "# Crear dataset pequeño de ejemplo con primeros 4 partidos\n",
    "N_EXAMPLE_MATCHES = 4\n",
    "X_small = []\n",
    "y_small = []\n",
    "for i, X_match in enumerate(X_all[:N_EXAMPLE_MATCHES]):\n",
    "    combined = combine_cameras(X_match, mode='min')\n",
    "    X_small.append(combined)\n",
    "    num_frames = combined.shape[0]\n",
    "    labels = annotations_to_frame_labels(y_all[i]['annotations'], num_frames, TARGET_EVENTS)\n",
    "    y_small.append(labels)\n",
    "\n",
    "# Normalizar features: calcular mean/std sobre X_small y aplicar\n",
    "# Esto suele mejorar la convergencia del modelo LSTM\n",
    "def compute_mean_std(X_list):\n",
    "    # X_list: lista de arrays (T, D)\n",
    "    all_concat = np.vstack([x for x in X_list])\n",
    "    mean = all_concat.mean(axis=0)\n",
    "    std = all_concat.std(axis=0) + 1e-6\n",
    "    return mean, std\n",
    "\n",
    "mean_feat, std_feat = compute_mean_std(X_small)\n",
    "print('feature dim:', mean_feat.shape[0])\n",
    "# aplicar normalización in-place creando nuevas matrices (no alterar original si deseas conservar)\n",
    "X_small = [(x - mean_feat) / std_feat for x in X_small]\n",
    "print('Normalized X_small using computed mean/std')\n",
    "\n",
    "# Dataset que acepta arrays ya combinados o listas de arrays\n",
    "class SoccerSequenceDataset(Dataset):\n",
    "    def __init__(self, X_matches, y_matches, seq_len=SEQUENCE_LENGTH, stride=STRIDE):\n",
    "        self.seq_len = seq_len\n",
    "        self.stride = stride\n",
    "        self.samples = []\n",
    "        self.combined = []\n",
    "        # X_matches puede contener arrays combinados (ndarray) o listas de arrays\n",
    "        for xm in X_matches:\n",
    "            if isinstance(xm, list):\n",
    "                self.combined.append(np.concatenate(xm, axis=1))\n",
    "            else:\n",
    "                self.combined.append(xm)\n",
    "        self.y_matches = y_matches\n",
    "        for midx, arr in enumerate(self.combined):\n",
    "            n = arr.shape[0]\n",
    "            for start in range(0, n - seq_len + 1, stride):\n",
    "                self.samples.append((midx, start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        midx, start = self.samples[idx]\n",
    "        x = self.combined[midx][start:start+self.seq_len]  # (seq_len, D)\n",
    "        y = self.y_matches[midx][start:start+self.seq_len]  # (seq_len, C)\n",
    "        # to tensors\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
    "\n",
    "# Crear DataLoader con los arrays ya combinados\n",
    "ds = SoccerSequenceDataset(X_small, y_small, seq_len=SEQUENCE_LENGTH, stride=STRIDE)\n",
    "loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
    "\n",
    "print('dataset samples:', len(ds))\n",
    "for xb, yb in loader:\n",
    "    print('batch x shape:', xb.shape, 'batch y shape:', yb.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f375d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (2422226349.py, line 120)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\u001b[39m\n          ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Modelo temporal rápido (Conv1D) + entrenamiento corto con split train/val\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "    import os\n",
    "    \n",
    "    class TemporalConvModel(nn.Module):\n",
    "        def __init__(self, input_dim, n_classes, hidden=256, dropout=0.2):\n",
    "            super().__init__()\n",
    "            # Conv1d expects (B, C_in, L); we permute before convs\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Conv1d(input_dim, hidden, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(hidden, hidden // 2, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "            self.fc = nn.Linear(hidden // 2, n_classes)\n",
    "        def forward(self, x):\n",
    "            # x: (B, T, D) -> conv needs (B, D, T)\n",
    "            x = x.permute(0, 2, 1)\n",
    "            out = self.net(x)  # (B, hidden2, T)\n",
    "            out = out.permute(0, 2, 1)  # (B, T, hidden2)\n",
    "            out = self.fc(out)  # (B, T, n_classes)\n",
    "            return out\n",
    "\n",
    "    # Preparar datos: split por partidos (train/val)\n",
    "    n_matches = len(X_small)\n",
    "    if n_matches < 2:\n",
    "        raise RuntimeError('Se necesitan al menos 2 partidos en X_small para train/val split')\n",
    "    split = int(0.75 * n_matches)\n",
    "    train_X = X_small[:split]\n",
    "    train_y = y_small[:split]\n",
    "    val_X = X_small[split:]\n",
    "    val_y = y_small[split:]\n",
    "\n",
    "    # recompute datasets and loaders\n",
    "    ds_train = SoccerSequenceDataset(train_X, train_y, seq_len=SEQUENCE_LENGTH, stride=STRIDE)\n",
    "    ds_val = SoccerSequenceDataset(val_X, val_y, seq_len=SEQUENCE_LENGTH, stride=STRIDE)\n",
    "    loader_train = DataLoader(ds_train, batch_size=8, shuffle=True)\n",
    "    loader_val = DataLoader(ds_val, batch_size=8, shuffle=False)\n",
    "\n",
    "    # compute pos_weight for BCE (balance classes) from train set\n",
    "    all_y_train = np.vstack([m.reshape(-1, m.shape[-1]) for m in train_y])\n",
    "    pos_counts = all_y_train.sum(axis=0)\n",
    "    neg_counts = all_y_train.shape[0] - pos_counts\n",
    "    pos_weights = []\n",
    "    for p, n in zip(pos_counts, neg_counts):\n",
    "        if p > 0:\n",
    "            pos_weights.append(float(n / p))\n",
    "        else:\n",
    "            pos_weights.append(1.0)\n",
    "    pos_weight_tensor = torch.tensor(pos_weights, dtype=torch.float32).to(torch.device('cpu'))\n",
    "\n",
    "    input_dim = X_small[0].shape[1]\n",
    "    n_classes = len(TARGET_EVENTS)\n",
    "    model = TemporalConvModel(input_dim, n_classes, hidden=256, dropout=0.2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor.to(device))\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Entrenar varias épocas y evaluar\n",
    "    N_EPOCHS = 10\n",
    "    import math\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        n_batches = 0\n",
    "        for xb, yb in loader_train:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "        avg_loss = total_loss / max(1, n_batches)\n",
    "        print(f'epoch {epoch} avg_loss {avg_loss:.4f}')\n",
    "\n",
    "        # evaluación en val\n",
    "        model.eval()\n",
    "        y_trues = []\n",
    "        y_probs = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in loader_val:\n",
    "                p = torch.sigmoid(model(xb.to(device))).cpu().numpy()\n",
    "                y_trues.append(yb.numpy().reshape(-1, yb.shape[-1]))\n",
    "                y_probs.append(p.reshape(-1, p.shape[-1]))\n",
    "        if len(y_trues) == 0:\n",
    "            print('No hay samples de validación en este split')\n",
    "            continue\n",
    "        y_trues = np.vstack(y_trues)\n",
    "        y_probs = np.vstack(y_probs)\n",
    "        for c, lab in enumerate(TARGET_EVENTS):\n",
    "            try:\n",
    "                auc = roc_auc_score(y_trues[:, c], y_probs[:, c])\n",
    "            except Exception:\n",
    "                auc = None\n",
    "            try:\n",
    "                ap = average_precision_score(y_trues[:, c], y_probs[:, c])\n",
    "            except Exception:\n",
    "                ap = None\n",
    "            f1_val = f1_score(y_trues[:, c], (y_probs[:, c] > 0.2).astype(int), zero_division=0)\n",
    "            print(f'Val - class {c} ({lab}): AUROC={auc} AP={ap} F1@0.2={f1_val}')\n",
    "\n",
    "    # Guardar checkpoint\n",
    "    ckpt_dir = 'checkpoints'\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(ckpt_dir, 'temporal_conv.pt'))\n",
    "    print('Saved checkpoint to', os.path.join(ckpt_dir, 'temporal_conv.pt'))\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print('PyTorch no está instalado en este entorno. Para instalar, ejecuta en PowerShell:')\n",
    "    print('CPU-only (Windows PowerShell):')\n",
    "    print('pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu')\n",
    "    print('DirectML (Intel Iris Xe, Windows) - experimental:')\n",
    "    print('pip install --upgrade pip')\n",
    "    print('pip install torch-directml -U')\n",
    "    print('Si usas conda o GPU, revisa https://pytorch.org/get-started/locally/')\n",
    "    print('Error:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
